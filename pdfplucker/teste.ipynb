{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8357f289-b061-461f-889b-aabc44670b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import json\n",
    "import fitz\n",
    "import time\n",
    "import multiprocessing  # Changed back to multiprocessing\n",
    "from pathlib import Path\n",
    "from concurrent.futures import as_completed, TimeoutError\n",
    "#from pdfplucker.utils import format_result, link_subtitles, get_safe_executor, logger, Data\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.document import ConversionResult\n",
    "from docling_core.types.doc import ImageRefMode\n",
    "from docling.exceptions import ConversionError\n",
    "from docling.datamodel.pipeline_options import (\n",
    "    AcceleratorDevice,\n",
    "    AcceleratorOptions,\n",
    "    PdfPipelineOptions,\n",
    "    EasyOcrOptions,\n",
    ")\n",
    "from docling_core.types.doc import (\n",
    "    PictureItem,\n",
    "    TableItem,\n",
    "    TextItem,\n",
    "    DocItemLabel,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c0e1919c-81f7-4919-ace9-efc117901397",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_converter(device : str = 'CPU', num_threads : int = 4, ocr_lang: list = ['es', 'pt'], force_ocr: bool = False) -> DocumentConverter:\n",
    "    ''' Create a DocumentConverter object with the pipeline options configured''' \n",
    "    pipeline_options = PdfPipelineOptions()\n",
    "    pipeline_options.do_ocr = True\n",
    "    pipeline_options.do_table_structure = True\n",
    "    pipeline_options.table_structure_options.do_cell_matching = True \n",
    "    pipeline_options.ocr_options.lang = ocr_lang\n",
    "    pipeline_options.generate_picture_images = True\n",
    "    pipeline_options.do_picture_classification = True\n",
    "    pipeline_options.do_formula_enrichment = True\n",
    "    #note yet pipeline_options.do_picture_description = True\n",
    "    \n",
    "    # Aggressive scaling for low memory mode\n",
    "    pipeline_options.images_scale = 1\n",
    "    \n",
    "    if force_ocr:\n",
    "        # Rapid OCR or Easy OCr\n",
    "        ocr_options = EasyOcrOptions(force_full_page_ocr=True, lang=ocr_lang)\n",
    "        pipeline_options.ocr_options = ocr_options\n",
    "    \n",
    "    # Device acceleration\n",
    "    device_type = AcceleratorDevice.CUDA if device.upper() == 'CUDA' else AcceleratorDevice.CPU if device.upper() == 'CPU' else AcceleratorDevice.AUTO if device.upper() == 'AUTO' else AcceleratorDevice.AUTO\n",
    "    pipeline_options.accelerator_options = AcceleratorOptions(num_threads=num_threads, device=device_type)\n",
    "    \n",
    "    converter = DocumentConverter(\n",
    "        format_options={\n",
    "            InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "780bdac1-864e-4eaf-962d-ee42c9956ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = create_converter('CPU', 1, force_ocr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ea0848-75ee-4bf0-863c-25cd3cdaa7a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "source=\"/home/rafael-dias/Downloads/legendado.pdf\"\n",
    "conv: ConversionResult = converter.convert(str(source)) # use str instead of Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42196eba-8f58-417f-976a-3a67f6016242",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from typing import TypedDict, List, Dict, Any\n",
    "import docling\n",
    "import traceback\n",
    "\n",
    "class Data(TypedDict):\n",
    "    metadata: Dict[str, Any]\n",
    "    pages: List[Dict[str, Any]]\n",
    "    images: List[Dict[str, Any]]\n",
    "    tables: List[Dict[str, Any]]\n",
    "    captions: List[Dict[str, Any]]\n",
    "\n",
    "def format_results(conv: ConversionResult, data: Data, filename: str, image_path: str) -> bool:\n",
    "    counter = 0\n",
    "    try:\n",
    "        for idx, (item, _) in enumerate(conv.document.iterate_items()):\n",
    "            if isinstance(item, TextItem):\n",
    "                page = item.prov[0].page_no\n",
    "                label = item.label\n",
    "                text = item.text\n",
    "\n",
    "                page_found = False\n",
    "                for page_dict in data['pages']:\n",
    "                    if page_dict['page_number'] == page:\n",
    "                        page_found = True\n",
    "                        if 'content' not in page_dict:\n",
    "                            page_dict['content'] = \"\"\n",
    "                        match label:\n",
    "                            case DocItemLabel.SECTION_HEADER:\n",
    "                                page_dict['content'] += f\"\\n#{text}\\n\"\n",
    "                            case DocItemLabel.FORMULA:\n",
    "                                page_dict['content'] += f\" Equation: {text}\\n\"\n",
    "                            case DocItemLabel.REFERENCE:\n",
    "                                page_dict['content'] += f\"\\nReference: {text}\\n\"\n",
    "                            case DocItemLabel.LIST_ITEM:\n",
    "                                page_dict['content'] += f\"\\n- {text}\\n\"\n",
    "                            case DocItemLabel.CAPTION:\n",
    "                                page_dict['content'] += f\"_{text}_\\n\"\n",
    "                                data['captions'].append({\n",
    "                                    'self_ref' : item.self_ref,\n",
    "                                    'cref' : item.parent.cref,\n",
    "                                    'text' : text\n",
    "                                })\n",
    "                            case DocItemLabel.FOOTNOTE:\n",
    "                                page_dict['content'] += f\"\\nFootnote: {text}\\n\"\n",
    "                            case DocItemLabel.TITLE:\n",
    "                                page_dict['content'] += f\"\\n##{text}_\\n\"\n",
    "                            case DocItemLabel.TEXT:\n",
    "                                page_dict['content'] += f\" {text}\"\n",
    "                            case _:\n",
    "                                page_dict['content'] += f\" {text}\"\n",
    "                        break\n",
    "                        \n",
    "                if not page_found:\n",
    "                    new_page = {'page_number': page, 'content': text}\n",
    "                    data['pages'].append(new_page)\n",
    "    \n",
    "            elif isinstance(item, TableItem):\n",
    "                table = item.export_to_markdown(doc=conv.document)\n",
    "                self_ref = item.self_ref\n",
    "                captions = item.captions\n",
    "                references = item.references\n",
    "                footnotes = item.footnotes\n",
    "                page = item.prov[0].page_no\n",
    "    \n",
    "                page_found = False\n",
    "                for page_dict in data['pages']:\n",
    "                    if page_dict['page_number'] == page:\n",
    "                        page_found = True\n",
    "                        if 'content' not in page_dict:\n",
    "                            page_dict['content'] = \"\"\n",
    "                        page_dict['content'] += f\" <{self_ref}> \"\n",
    "                if not page_found:\n",
    "                    new_page = {'page_number': page, 'content': f\" <{self_ref}> \"}\n",
    "                    data['pages'].append(new_page)\n",
    "    \n",
    "                data['tables'].append({\n",
    "                    'self_ref' : self_ref,\n",
    "                    'captions' : captions,\n",
    "                    'caption' : \"\",\n",
    "                    'references' : references,\n",
    "                    'footnotes' : footnotes,\n",
    "                    'page' : page, \n",
    "                    'table' : table\n",
    "                })\n",
    "    \n",
    "            elif isinstance(item, PictureItem):\n",
    "                self_ref = item.self_ref\n",
    "                captions = item.captions\n",
    "                references = item.references\n",
    "                footnotes = item.footnotes\n",
    "                page = item.prov[0].page_no\n",
    "                classification = None\n",
    "                confidence = None\n",
    "                if item.annotations:\n",
    "                    for annotation in item.annotations:\n",
    "                        if annotation.kind == 'classification':\n",
    "                            # Find the classification with the highest confidence\n",
    "                            best_class = max(\n",
    "                                annotation.predicted_classes,\n",
    "                                key=lambda cls: cls.confidence\n",
    "                            )\n",
    "                            classification = best_class.class_name,\n",
    "                            confidence = best_class.confidence\n",
    "                            break\n",
    "                image_filename = (image_path / f\"{filename}_{counter}.png\")\n",
    "                placeholder = f\"{filename}_{counter}.png\"\n",
    "                with image_filename.open('wb') as file:\n",
    "                    item.get_image(conv.document).save(file, \"PNG\")\n",
    "                data['images'].append({\n",
    "                    'ref': placeholder,\n",
    "                    'self_ref' : self_ref,\n",
    "                    'captions' : captions,\n",
    "                    'caption' : \"\",\n",
    "                    'classification' : classification,\n",
    "                    'confidence' : confidence,\n",
    "                    'references' : references,\n",
    "                    'footnotes' : footnotes,\n",
    "                    'page' : page,\n",
    "                })\n",
    "                counter += 1\n",
    "    \n",
    "                page_found = False\n",
    "                for page_dict in data['pages']:\n",
    "                    if page_dict['page_number'] == page:\n",
    "                        page_found = True\n",
    "                        if 'content' not in page_dict:\n",
    "                            page_dict['content'] = \"\"\n",
    "                        page_dict['content'] += f\" <{placeholder}> \"\n",
    "                if not page_found:\n",
    "                    new_page = {'page_number': page, 'content': f\" <{placeholder}> \"}\n",
    "                    data['pages'].append(new_page)\n",
    "\n",
    "\n",
    "        caption_dict = {caption[\"cref\"]: caption[\"text\"] for caption in data.get(\"captions\", [])}\n",
    "    \n",
    "        for image in data.get(\"images\", []):\n",
    "            self_ref = image.get(\"self_ref\")\n",
    "            if self_ref in caption_dict:\n",
    "                caption_text = caption_dict[self_ref]\n",
    "                if caption_text not in image.get(\"captions\", []):\n",
    "                    imagem[\"caption\"] += caption_text\n",
    "\n",
    "        \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        traceback.print_exc()\n",
    "\n",
    "\n",
    "def json_serializable(obj):\n",
    "    \"\"\"Função auxiliar para tornar objetos personalizados serializáveis em JSON.\"\"\"\n",
    "    if hasattr(obj, '__dict__'):\n",
    "        return obj.__dict__\n",
    "    else:\n",
    "        return str(obj)\n",
    "\n",
    "data: Data = {\n",
    "    \"metadata\": {},\n",
    "    \"pages\" : [],\n",
    "    \"images\": [],\n",
    "    \"tables\": [],\n",
    "    \"captions\" : []\n",
    "}\n",
    "format_results(conv, data, Path(\"filename\"), Path(\"./\"))\n",
    "# Correção 2: Adicionando default=json_serializable ao json.dumps\n",
    "print(json.dumps(data, indent=4, ensure_ascii=False, default=json_serializable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cad21f-ab93-4c95-ab2e-9e76e907e208",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
